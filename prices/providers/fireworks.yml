# yaml-language-server: $schema=.schema.json
name: Fireworks
id: fireworks
pricing_urls:
  - https://fireworks.ai/pricing
api_pattern: 'https://api\.fireworks\.ai'
model_match:
  starts_with: accounts/fireworks/models/

models:
  - id: deepseek-r1-0528
    name: DeepSeek R1 0528
    description: >-
      The updated DeepSeek-R1-0528 model delivers major improvements in reasoning, inference, and accuracy through enhanced post-training optimization and greater computational resources. It now performs at a level approaching top-tier models like O3 and Gemini 2.5 Pro, with notable gains in complex tasks such as math and programming.
    match:
      equals: accounts/fireworks/models/deepseek-r1-0528
    context_window: 160000
    prices_checked: 2025-07-13
    prices:
      input_mtok: 3
      output_mtok: 8

  - id: deepseek-v3-0324
    name: Deepseek V3 03-24
    description: >-
      A strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token from Deepseek. Updated checkpoint.
    match:
      equals: accounts/fireworks/models/deepseek-v3-0324
    context_window: 160000
    prices_checked: 2025-07-13
    price_comments: docs give just one price - "Pricing Per 1M Tokens", we assume that's input and output
    prices:
      input_mtok: 0.9
      output_mtok: 0.9

  - id: gemma-3-27b-it
    name: Gemma 3 27B Instruct
    match:
      equals: accounts/fireworks/models/gemma-3-27b-it
    context_window: 131000
    prices_checked: 2025-07-13
    price_comments: docs give just one price - "Pricing Per 1M Tokens", we assume that's input and output
    prices:
      input_mtok: 0.1
      output_mtok: 0.1

  - id: llama-v3p1-8b-instruct
    name: Llama 3.1 8B Instruct
    description: >-
      The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models in 8B, 70B and 405B sizes. The Llama 3.1 instruction tuned text only models (8B, 70B, 405B) are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.
    match:
      equals: accounts/fireworks/models/llama-v3p1-8b-instruct
    context_window: 131000
    prices_checked: 2025-07-13
    price_comments: docs give just one price - "Pricing Per 1M Tokens", we assume that's input and output
    prices:
      input_mtok: 0.2
      output_mtok: 0.2

  - id: llama4-maverick-instruct-basic
    name: Llama 4 Maverick Instruct (Basic)
    description: >-
      The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models in 8B, 70B and 405B sizes. The Llama 3.1 instruction tuned text only models (8B, 70B, 405B) are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.
    match:
      equals: accounts/fireworks/models/llama4-maverick-instruct-basic
    context_window: 1000000
    prices_checked: 2025-07-13
    prices:
      input_mtok: 0.22
      output_mtok: 0.88

  - id: qwen2p5-vl-72b-instruct
    name: Qwen2.5-VL 72B Instruct
    description: Latest Qwen's VLM model
    match:
      equals: accounts/fireworks/models/qwen2p5-vl-72b-instruct
    context_window: 128000
    prices_checked: 2025-07-13
    price_comments: docs give just one price - "Pricing Per 1M Tokens", we assume that's input and output
    prices:
      input_mtok: 0.9
      output_mtok: 0.9

  - id: qwen3-235b-a22b
    name: Qwen3 235B-A22B
    description: >-
      Qwen3 is the latest evolution in the Qwen LLM series, featuring both dense and MoE models with major advancements in reasoning, agent capabilities, multilingual support, and instruction following. It uniquely allows seamless switching between "thinking" (for complex logic, math, coding) and "non-thinking" modes (for fast, general dialogue), delivering strong performance across tasks.
    match:
      equals: accounts/fireworks/models/qwen3-235b-a22b
    context_window: 128000
    prices_checked: 2025-07-13
    prices:
      input_mtok: 0.22
      output_mtok: 0.88
