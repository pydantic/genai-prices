import pytest
from inline_snapshot import snapshot

from genai_prices.calc import find_provider_by_id
from genai_prices.data import providers

mark_xfail_todo = pytest.mark.xfail(reason='todo')

# Cases with xfail I think we can/should probably support eventually
test_cases: list[tuple[str, str, str]] = [
    ('openai', 'gpt-4o-mini', snapshot(('openai', 'gpt-4o-mini'))),
    ('openai', 'gpt-4.1', snapshot(('openai', 'gpt-4.1'))),
    ('openai', 'gpt-4o-mini-2024-07-18', snapshot(('openai', 'gpt-4o-mini'))),
    ('openai', 'gpt-4.1-mini', snapshot(('openai', 'gpt-4.1-mini'))),
    ('openai', 'gpt-4.1-mini-2025-04-14', snapshot(('openai', 'gpt-4.1-mini'))),
    ('openai', 'gpt-4o', snapshot(('openai', 'gpt-4o'))),
    ('openai', 'gpt-4o-2024-08-06', snapshot(('openai', 'gpt-4o'))),
    ('openai', 'gpt-4o-2024-11-20', snapshot(('openai', 'gpt-4o'))),
    ('openai', 'gpt-4.1-nano-2025-04-14', snapshot(('openai', 'gpt-4.1-nano'))),
    ('openai', 'gpt-4.1-nano', snapshot(('openai', 'gpt-4.1-nano'))),
    ('openai', 'gpt-3.5-turbo-0125', snapshot(('openai', 'gpt-3.5-turbo'))),
    ('google-vertex', 'gemini-2.5-flash', snapshot(('google', 'gemini-2.5-flash'))),
    ('openai', 'text-embedding-ada-002', snapshot(('openai', 'text-embedding-ada-002'))),
    ('openai', 'text-embedding-ada-002-v2', snapshot(('openai', 'text-embedding-ada-002'))),
    ('openai', 'gpt-4.1-2025-04-14', snapshot(('openai', 'gpt-4.1'))),
    ('google-gla', 'gemini-2.0-flash', snapshot(('google', 'gemini-2.0-flash'))),
    ('anthropic', 'claude-3-7-sonnet-20250219', snapshot(('anthropic', 'claude-3-7-sonnet-latest'))),
    ('google-gla', 'gemini-2.5-flash', snapshot(('google', 'gemini-2.5-flash'))),
    ('openai', 'o3', snapshot(('openai', 'o3'))),
    ('google-gla', 'gemini-2.0-flash-lite', snapshot(('google', 'gemini-2.0-flash'))),
    ('openai', 'text-embedding-3-small', snapshot(('openai', 'text-embedding-3-small'))),
    ('openai', 'o3-2025-04-16', snapshot(('openai', 'o3'))),
    ('anthropic', 'claude-sonnet-4-20250514', snapshot(('anthropic', 'claude-sonnet-4-0'))),
    ('vertex_ai', 'gemini-2.5-flash', snapshot(('google', 'gemini-2.5-flash'))),
    ('google-vertex', 'gemini-2.5-pro', snapshot(('google', 'gemini-2.5-pro'))),
    ('openai', 'o4-mini-2025-04-16', snapshot(('openai', 'o4-mini'))),
    ('google-vertex', 'gemini-2.0-flash', snapshot(('google', 'gemini-2.0-flash'))),
    ('openai', 'o4-mini', snapshot(('openai', 'o4-mini'))),
    ('openai', 'text-embedding-3-large', snapshot(('openai', 'text-embedding-3-large'))),
    pytest.param(
        'google-vertex',
        'publishers/google/models/gemini-2.5-flash-lite',
        snapshot(),
        marks=mark_xfail_todo,
    ),
    ('vertex_ai', 'gemini-2.5-pro', snapshot(('google', 'gemini-2.5-pro'))),
    ('google-vertex', 'gemini-2.0-flash-lite', snapshot(('google', 'gemini-2.0-flash'))),
    ('google-vertex', 'gemini-2.5-flash-lite', snapshot(('google', 'gemini-2.5-flash-lite'))),
    pytest.param('bedrock', 'us.meta.llama4-maverick-17b-instruct-v1:0', snapshot(), marks=mark_xfail_todo),
    ('openai', 'o3-mini-2025-01-31', snapshot(('openai', 'o3-mini'))),
    ('google', 'gemini-2.5-flash', snapshot(('google', 'gemini-2.5-flash'))),
    ('openai', 'o3-mini', snapshot(('openai', 'o3-mini'))),
    pytest.param('google-vertex', 'publishers/google/models/gemini-2.5-flash', snapshot(), marks=mark_xfail_todo),
    ('google-gla', 'gemini-2.5-pro', snapshot(('google', 'gemini-2.5-pro'))),
    ('google-gla', 'gemini-2.5-flash-preview-05-20', snapshot(('google', 'gemini-2.5-flash-preview'))),
    ('anthropic', 'claude-3-5-sonnet-latest', snapshot(('anthropic', 'claude-3-5-sonnet'))),
    pytest.param('bedrock', 'us.anthropic.claude-sonnet-4-20250514-v1:0', snapshot(), marks=mark_xfail_todo),
    ('anthropic', 'claude-3-5-sonnet-20241022', snapshot(('anthropic', 'claude-3-5-sonnet'))),
    ('anthropic', 'claude-sonnet-4-0', snapshot(('anthropic', 'claude-sonnet-4-0'))),
    ('gcp.vertex.agent', 'gemini-2.5-pro', snapshot(('google', 'gemini-2.5-pro'))),
    ('google-gla', 'models/gemini-2.5-flash-preview-05-20', snapshot(('google', 'gemini-2.5-flash-preview'))),
    pytest.param('bedrock', 'us.anthropic.claude-3-7-sonnet-20250219-v1:0', snapshot(), marks=mark_xfail_todo),
    ('anthropic', 'claude-opus-4-1-20250805', snapshot(('anthropic', 'claude-opus-4-1'))),
    ('google', 'gemini-2.5-flash-lite', snapshot(('google', 'gemini-2.5-flash-lite'))),
    ('anthropic', 'claude-3-5-haiku-latest', snapshot(('anthropic', 'claude-3-5-haiku-latest'))),
    ('anthropic', 'claude-4-sonnet-20250514', snapshot(('anthropic', 'claude-sonnet-4-0'))),
    ('google-vertex', 'publishers/google/models/gemini-2.0-flash-lite-001', snapshot(('google', 'gemini-2.0-flash'))),
    ('anthropic.messages', 'claude-sonnet-4-20250514', snapshot(('anthropic', 'claude-sonnet-4-0'))),
    ('google-vertex', 'publishers/google/models/gemini-2.0-flash-lite', snapshot(('google', 'gemini-2.0-flash'))),
    ('vertex_ai', 'gemini-2.0-flash', snapshot(('google', 'gemini-2.0-flash'))),
    ('mistral_ai', 'mistral-small-2506', snapshot(('mistral', 'mistral-small'))),
    pytest.param('groq', 'llama-3.3-70b-versatile', snapshot(), marks=mark_xfail_todo),
    pytest.param('bedrock', 'us.meta.llama3-3-70b-instruct-v1:0', snapshot(), marks=mark_xfail_todo),
    ('anthropic', 'claude-3-7-sonnet-latest', snapshot(('anthropic', 'claude-3-7-sonnet-latest'))),
    ('vertex_ai', 'gemini-2.0-flash-001', snapshot(('google', 'gemini-2.0-flash'))),
    ('google-gla', 'gemini-2.5-flash-lite', snapshot(('google', 'gemini-2.5-flash-lite'))),
    ('Google', 'gemini-2.5-pro', snapshot(('google', 'gemini-2.5-pro'))),
    ('openai', 'gpt-4o-mini-search-preview', snapshot(('openai', 'gpt-4o-mini'))),
    pytest.param('bedrock', 'anthropic.claude-3-5-haiku-20241022-v1:0', snapshot(), marks=mark_xfail_todo),
    ('openai', 'gpt-3.5-turbo', snapshot(('openai', 'gpt-3.5-turbo'))),
    ('openai', 'o4-mini-deep-research-2025-06-26', snapshot(('openai', 'o4-mini'))),
    ('Google', 'gemini-2.5-flash', snapshot(('google', 'gemini-2.5-flash'))),
    ('google-vertex', 'gemini-2.0-flash-lite-001', snapshot(('google', 'gemini-2.0-flash'))),
    pytest.param(
        'bedrock',
        'arn:aws:bedrock:us-east-1:203095961504:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0',
        snapshot(),
        marks=mark_xfail_todo,
    ),
    ('google-gla', 'gemini-2.0-flash-001', snapshot(('google', 'gemini-2.0-flash'))),
    ('anthropic', 'claude-3-5-haiku-20241022', snapshot(('anthropic', 'claude-3-5-haiku-latest'))),
    ('google-gla', 'gemini-2.5-flash-lite-preview-06-17', snapshot(('google', 'gemini-2.5-flash-lite'))),
    pytest.param('bedrock', 'us.anthropic.claude-3-5-haiku-20241022-v1:0', snapshot(), marks=mark_xfail_todo),
    ('openai', 'gpt-4-turbo-preview', snapshot(('openai', 'gpt-4-turbo'))),
    ('google-vertex', 'publishers/google/models/gemini-2.0-flash', snapshot(('google', 'gemini-2.0-flash'))),
    ('anthropic', 'claude-opus-4-20250514', snapshot(('anthropic', 'claude-opus-4-0'))),
    pytest.param('bedrock', 'eu.anthropic.claude-sonnet-4-20250514-v1:0', snapshot(), marks=mark_xfail_todo),
    pytest.param('bedrock', 'us.meta.llama3-2-90b-instruct-v1:0', snapshot(), marks=mark_xfail_todo),
    ('openai', 'gpt-4o-2024-05-13', snapshot(('openai', 'gpt-4o'))),
    ('google-gla', 'gemini-1.5-flash', snapshot(('google', 'gemini-1.5-flash'))),
    pytest.param('groq', 'moonshotai/kimi-k2-instruct', snapshot(), marks=mark_xfail_todo),
    ('anthropic', 'claude-opus-4-0', snapshot(('anthropic', 'claude-opus-4-0'))),
    ('anthropic', 'claude-sonnet-4@20250514', snapshot(('anthropic', 'claude-sonnet-4-0'))),
    pytest.param('bedrock', 'amazon.nova-pro-v1:0', snapshot(), marks=mark_xfail_todo),
    ('google-vertex', 'gemini-2.0-flash-001', snapshot(('google', 'gemini-2.0-flash'))),
    pytest.param('google-vertex', 'publishers/google/models/gemini-2.5-pro', snapshot(), marks=mark_xfail_todo),
    ('openai', 'gpt-4', snapshot(('openai', 'gpt-4'))),
    ('gemini', 'gemini-2.5-flash-lite', snapshot(('google', 'gemini-2.5-flash-lite'))),
    pytest.param('bedrock', 'amazon.nova-micro-v1:0', snapshot(), marks=mark_xfail_todo),
    pytest.param('bedrock', 'anthropic.claude-3-5-sonnet-20241022-v2:0', snapshot(), marks=mark_xfail_todo),
    pytest.param(
        'bedrock',
        'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-5-haiku-20241022-v1:0',
        None,
        marks=mark_xfail_todo,
    ),
    pytest.param('groq', 'qwen/qwen3-32b', snapshot(), marks=mark_xfail_todo),
    ('gcp.vertex.agent', 'gemini-2.5-flash-preview-05-20', snapshot(('google', 'gemini-2.5-flash-preview'))),
    pytest.param('groq', 'llama-3.1-8b-instant', snapshot(), marks=mark_xfail_todo),
    pytest.param('groq', 'meta-llama/llama-4-scout-17b-16e-instruct', snapshot(), marks=mark_xfail_todo),
    ('gemini', 'gemini-2.5-pro', snapshot(('google', 'gemini-2.5-pro'))),
    ('anthropic', 'claude-4-opus-20250514', snapshot(('anthropic', 'claude-opus-4-0'))),
    ('gcp.vertex.agent', 'gemini-2.5-flash', snapshot(('google', 'gemini-2.5-flash'))),
    ('gemini', 'gemini-2.5-flash', snapshot(('google', 'gemini-2.5-flash'))),
    ('openai', 'gpt-4-0613', snapshot(('openai', 'gpt-4'))),
    ('perplexity', 'sonar', snapshot(('perplexity', 'sonar'))),
    pytest.param('groq', 'deepseek-r1-distill-llama-70b', snapshot(), marks=mark_xfail_todo),
    ('azure', 'gpt-4.1', snapshot(('azure', 'gpt-4.1'))),
    ('azure', 'gpt-4.1-2025-04-14', snapshot(('azure', 'gpt-4.1'))),
    ('openai', 'gpt-4-turbo', snapshot(('openai', 'gpt-4-turbo'))),
    pytest.param('cartesia', 'sonic-2', snapshot(), marks=mark_xfail_todo),
    pytest.param('bedrock', 'anthropic.claude-3-5-sonnet-20240620-v1:0', snapshot(), marks=mark_xfail_todo),
    ('google-gla', 'gemini-2.0-flash-latest', snapshot(('google', 'gemini-2.0-flash'))),
    ('openai', 'o1', snapshot(('openai', 'o1'))),
    pytest.param('groq', 'meta-llama/llama-4-maverick-17b-128e-instruct', snapshot(), marks=mark_xfail_todo),
    ('openai', 'gpt-4-turbo-2024-04-09', snapshot(('openai', 'gpt-4-turbo'))),
    ('gemini', 'gemini-2.0-flash', snapshot(('google', 'gemini-2.0-flash'))),
    ('deepseek', 'deepseek-reasoner', snapshot(('deepseek', 'deepseek-reasoner'))),
    ('anthropic', 'claude-3-5-sonnet-20240620', snapshot(('anthropic', 'claude-3-5-sonnet'))),
    pytest.param(
        'bedrock',
        'arn:aws:bedrock:us-west-2:726623243771:inference-profile/us.anthropic.claude-sonnet-4-20250514-v1:0',
        snapshot(),
        marks=mark_xfail_todo,
    ),
    ('google-gla', 'gemini-2.5-pro-preview-03-25', snapshot(('google', 'gemini-2.5-pro'))),
    pytest.param('bedrock', 'us.anthropic.claude-3-5-sonnet-20240620-v1:0', snapshot(), marks=mark_xfail_todo),
    pytest.param('bedrock', 'meta.llama3-1-70b-instruct-v1:0', snapshot(), marks=mark_xfail_todo),
    ('google-vertex-search', 'gemini-2.5-flash', snapshot(('google', 'gemini-2.5-flash'))),
    pytest.param('deepgram', 'nova-3-general', snapshot(), marks=mark_xfail_todo),
    ('gemini', 'gemini-1.5-flash-latest', snapshot(('google', 'gemini-1.5-flash'))),
    ('groq', 'openai/gpt-oss-20b', snapshot(('groq', 'openai/gpt-oss-20b'))),
    ('openai', 'o1-2024-12-17', snapshot(('openai', 'o1'))),
    ('xai', 'grok-3-mini', snapshot(('x-ai', 'grok-3-mini'))),
    ('anthropic', 'claude-sonnet-4', snapshot(('anthropic', 'claude-sonnet-4-0'))),
    ('openai', 'gpt-4-0125-preview', snapshot(('openai', 'gpt-4-turbo'))),
    pytest.param('bedrock', 'apac.anthropic.claude-3-5-sonnet-20241022-v2:0', snapshot(), marks=mark_xfail_todo),
    ('mistral_ai', 'mistral-large-2411', snapshot(('mistral', 'mistral-large'))),
    pytest.param('bedrock', 'us.amazon.nova-pro-v1:0', snapshot(), marks=mark_xfail_todo),
    ('anthropic', 'claude-3-opus', snapshot(('anthropic', 'claude-3-opus-latest'))),
    pytest.param('bedrock', 'eu.anthropic.claude-3-7-sonnet-20250219-v1:0', snapshot(), marks=mark_xfail_todo),
    ('mistral_ai', 'pixtral-large-2411', snapshot(('mistral', 'pixtral-large'))),
    ('mistral_ai', 'mistral-medium', snapshot(('mistral', 'mistral-medium-3'))),
    pytest.param('perplexity', 'perplexity/sonar', snapshot(), marks=mark_xfail_todo),
    ('openrouter', 'google/gemini-2.0-flash-001', snapshot(('openrouter', 'google/gemini-2.0-flash-001'))),
    pytest.param('openrouter', 'openrouter/google/gemini-2.0-flash-001', snapshot(), marks=mark_xfail_todo),
    ('openai', 'ft:gpt-4o-2024-08-06:org-id::A112', snapshot(('openai', 'ft:gpt-4o-2024-08-06:'))),
    ('anthropic.messages', 'claude-opus-4-20250514', snapshot(('anthropic', 'claude-opus-4-0'))),
    ('mistral_ai', 'open-mistral-nemo', snapshot(('mistral', 'mistral-nemo'))),
    ('anthropic', 'claude-3-haiku-20240307', snapshot(('anthropic', 'claude-3-haiku'))),
    ('google-gla', 'gemini-2.5-pro-preview-06-05', snapshot(('google', 'gemini-2.5-pro'))),
    ('groq', 'gemma2-9b-it', snapshot(('groq', 'gemma2-9b-it'))),
    ('groq', 'openai/gpt-oss-120b', snapshot(('groq', 'openai/gpt-oss-120b'))),
    ('google-gla', 'gemini-2.0-flash-lite-preview-02-05', snapshot(('google', 'gemini-2.0-flash'))),
    ('google-gla', 'gemini-2.5-pro-preview-05-06', snapshot(('google', 'gemini-2.5-pro'))),
    ('gcp.vertex.agent', 'gemini-2.5-flash-lite', snapshot(('google', 'gemini-2.5-flash-lite'))),
    ('google-gla', 'gemini-2.0-flash-lite-001', snapshot(('google', 'gemini-2.0-flash'))),
    ('gemini', 'gemini-2.5-flash-lite-preview-06-17', snapshot(('google', 'gemini-2.5-flash-lite'))),
    ('openai', 'gpt-4-1106-preview', snapshot(('openai', 'gpt-4-turbo'))),
    ('azure', 'gpt-4.1-mini', snapshot(('azure', 'gpt-4.1-mini'))),
    ('azure', 'gpt-4.1-mini-2025-04-14', snapshot(('azure', 'gpt-4.1-mini'))),
    ('gemini', 'gemini-2.5-pro-preview-06-05', snapshot(('google', 'gemini-2.5-pro'))),
    (
        'openrouter',
        'mistralai/mistral-7b-instruct:free',
        snapshot(('openrouter', 'mistralai/mistral-7b-instruct:free')),
    ),
    ('mistral_ai', 'ministral-8b-2410', snapshot(('mistral', 'ministral-8b'))),
    ('openai', 'chatgpt-4o-latest', snapshot(('openai', 'chatgpt-4o-latest'))),
    ('gemini', 'gemini-2.5-flash-preview-05-20', snapshot(('google', 'gemini-2.5-flash-preview'))),
    (
        'openai',
        'ft:gpt-4o-2024-08-06:ting-ai:noob:B85223',
        snapshot(('openai', 'ft:gpt-4o-2024-08-06:')),
    ),
    pytest.param('aws.bedrock', 'us.amazon.nova-micro-v1:0', snapshot(), marks=mark_xfail_todo),
    ('openai', 'gpt-4o-audio-preview', snapshot(('openai', 'gpt-4o-audio-preview'))),
    pytest.param('nebius', 'meta-llama/Llama-3.3-70B-Instruct', snapshot(), marks=mark_xfail_todo),
    ('google-gla', 'gemini-1.5-pro', snapshot(('google', 'gemini-1.5-pro'))),
    pytest.param('nebius', 'meta-llama/Meta-Llama-3.1-8B-Instruct', snapshot(), marks=mark_xfail_todo),
    ('openai', 'o4-mini-deep-research', snapshot(('openai', 'o4-mini'))),
    pytest.param('nebius', 'deepseek-ai/DeepSeek-R1-0528', snapshot(), marks=mark_xfail_todo),
    ('openai.chat', 'o3-mini-2025-01-31', snapshot(('openai', 'o3-mini'))),
    ('openai.chat', 'o3-mini', snapshot(('openai', 'o3-mini'))),
    ('openrouter', 'deepseek/deepseek-chat-v3-0324', snapshot(('openrouter', 'deepseek/deepseek-chat-v3-0324'))),
    pytest.param('nebius', 'nebius/deepseek-ai/DeepSeek-R1-0528', snapshot(), marks=mark_xfail_todo),
    pytest.param('nebius', 'llama-3.1-8b-instant', snapshot(), marks=mark_xfail_todo),
    pytest.param('litellm', 'gpt-4o-mini-2024-07-18', snapshot(), marks=mark_xfail_todo),
    pytest.param('litellm', 'gpt-4o-mini', snapshot(), marks=mark_xfail_todo),
    pytest.param('groq', 'nebius/meta-llama/Llama-3.3-70B-Instruct', snapshot(), marks=mark_xfail_todo),
    ('mistral_ai', 'mistral-embed', snapshot(('mistral', 'mistral-embed'))),
    pytest.param('openrouter', 'anthropic/claude-sonnet-4', snapshot(), marks=mark_xfail_todo),
    pytest.param('openrouter', 'google/gemini-2.5-flash', snapshot(), marks=mark_xfail_todo),
    ('perplexity', 'sonar-pro', snapshot(('perplexity', 'sonar-pro'))),
    pytest.param('nebius', 'nebius/meta-llama/Llama-3.3-70B-Instruct', snapshot(), marks=mark_xfail_todo),
    pytest.param('perplexity', 'perplexity/sonar-pro', snapshot(), marks=mark_xfail_todo),
    ('mistral_ai', 'mistral-medium-2505', snapshot(('mistral', 'mistral-medium-3'))),
    ('google-gla', 'gemini-2.5-flash-preview-04-17', snapshot(('google', 'gemini-2.5-flash-preview'))),
    pytest.param('groq', 'meta-llama/llama-guard-4-12b', snapshot(), marks=mark_xfail_todo),
    ('azure', 'o3-mini', snapshot(('azure', 'o3-mini'))),
    pytest.param('bedrock', 'us.anthropic.claude-3-5-sonnet-20241022-v2:0', snapshot(), marks=mark_xfail_todo),
    ('google-gla', 'gemini-1.5-pro-002', snapshot(('google', 'gemini-1.5-pro'))),
    ('groq', 'llama3-70b-8192', snapshot(('groq', 'llama3-70b-8192'))),
    ('azure', 'o4-mini', snapshot(('azure', 'o4-mini'))),
    pytest.param('nebius', 'llama-3.3-70b-versatile', snapshot(), marks=mark_xfail_todo),
    pytest.param('openrouter', 'openai/gpt-oss-120b', snapshot(), marks=mark_xfail_todo),
    ('google-gla', 'gemini-2.0-flash-exp', snapshot(('google', 'gemini-2.0-flash'))),
    ('deepseek', 'deepseek-chat', snapshot(('deepseek', 'deepseek-chat'))),
    pytest.param('groq', 'nebius/meta-llama/Meta-Llama-3.1-8B-Instruct', snapshot(), marks=mark_xfail_todo),
    pytest.param('azure', 'DeepSeek-R1-0528', snapshot(), marks=mark_xfail_todo),
    pytest.param('bedrock', 'us.amazon.nova-lite-v1:0', snapshot(), marks=mark_xfail_todo),
    ('mistral_ai', 'magistral-small-2507', snapshot(('mistral', 'magistral-small'))),
    pytest.param(
        'bedrock',
        'arn:aws:bedrock:us-west-2:726623243771:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0',
        snapshot(),
        marks=mark_xfail_todo,
    ),
    pytest.param('nebius', 'Qwen/Qwen3-32B', snapshot(), marks=mark_xfail_todo),
    ('gemini', 'models/gemini-2.5-flash-preview-05-20', snapshot(('google', 'gemini-2.5-flash-preview'))),
    pytest.param('bedrock', 'anthropic.claude-sonnet-4-20250514-v1:0', snapshot(), marks=mark_xfail_todo),
    ('groq', 'llama3-8b-8192', snapshot(('groq', 'llama3-8b-8192'))),
    ('anthropic', "claude-sonnet-4-0'", snapshot(('anthropic', 'claude-sonnet-4-0'))),
    ('openai', 'gpt-3.5-turbo-instruct', snapshot(('openai', 'gpt-3.5-turbo-instruct'))),
    ('google', 'gemini/gemini-2.0-flash', snapshot(('google', 'gemini-2.0-flash'))),
    ('google', 'gemini-2.0-flash', snapshot(('google', 'gemini-2.0-flash'))),
    ('anthropic', 'claude-4-sonnet-latest', snapshot(('anthropic', 'claude-sonnet-4-0'))),
    ('vertex_ai', 'gemini-2.5-flash-lite', snapshot(('google', 'gemini-2.5-flash-lite'))),
    ('openai', 'gpt-4o-realtime', snapshot(('openai', 'gpt-4o-realtime-preview'))),
    pytest.param('azure', 'DeepSeek-r1-0528', snapshot(), marks=mark_xfail_todo),
    ('google-vertex', 'gemini-1.5-pro-002', snapshot(('google', 'gemini-1.5-pro'))),
    ('gemini', 'gemini-2.0-flash-001', snapshot(('google', 'gemini-2.0-flash'))),
    ('mistral_ai', 'mistral-7b', snapshot(('mistral', 'mistral-7b'))),
    ('mistral_ai', 'mistral-large', snapshot(('mistral', 'mistral-large'))),
    pytest.param('azure', 'deepseek-r1', snapshot(), marks=mark_xfail_todo),
    pytest.param('deepinfra', 'deepseek-ai/DeepSeek-R1-0528', snapshot(), marks=mark_xfail_todo),
    pytest.param('deepinfra', 'deepinfra/deepseek-ai/DeepSeek-R1-0528', snapshot(), marks=mark_xfail_todo),
    pytest.param('perplexity', 'perplexity/sonar-deep-research', snapshot(), marks=mark_xfail_todo),
    pytest.param('huggingface', 'moonshotai/Kimi-K2-Instruct', snapshot(), marks=mark_xfail_todo),
    ('perplexity', 'sonar-deep-research', snapshot(('perplexity', 'sonar-deep-research'))),
    ('anthropic', 'claude-4-sonnet', snapshot(('anthropic', 'claude-sonnet-4-0'))),
    pytest.param('bedrock', 'meta.llama3-70b-instruct-v1:0', snapshot(), marks=mark_xfail_todo),
    pytest.param('bedrock', 'meta.llama3-2-90b-instruct-v1:0', snapshot(), marks=mark_xfail_todo),
    ('mistral_ai', 'magistral-medium', snapshot(('mistral', 'magistral-medium'))),
    pytest.param('groq', 'nebius/Qwen/Qwen3-32B', snapshot(), marks=mark_xfail_todo),
    ('gcp.vertex.agent', 'gemini-2.0-flash', snapshot(('google', 'gemini-2.0-flash'))),
    ('google-gla', 'gemma-3n-e4b-it', snapshot(('google', 'gemma-3n'))),
    ('google-gla', 'gemini-2.5-flash-latest', snapshot(('google', 'gemini-2.5-flash'))),
    pytest.param('bedrock', 'anthropic.claude-3-sonnet-20240229-v1:0', snapshot(), marks=mark_xfail_todo),
    ('anthropic', 'Claude-Sonnet-4', snapshot(('anthropic', 'claude-sonnet-4-0'))),
    ('anthropic', 'claude-sonnet-4', snapshot(('anthropic', 'claude-sonnet-4-0'))),
    ('xai', 'grok-4-0709', snapshot(('x-ai', 'grok-4-0709'))),
    ('google-gla', 'gemini-2.0-flash-exp:free', snapshot(('google', 'gemini-2.0-flash'))),
    ('google-gla', 'google-gla:gemini-2.0-flash', snapshot(('google', 'gemini-2.0-flash'))),
    ('mistral_ai', 'Mixtral-8x7B-v0.1', snapshot(('mistral', 'mixtral-8x7b'))),
    ('anthropic', 'claude-3-7-sonnet', snapshot(('anthropic', 'claude-3-7-sonnet-latest'))),
    pytest.param('openrouter', 'qwen/qwen3-coder', snapshot(), marks=mark_xfail_todo),
    pytest.param('bedrock', 'us.meta.llama4-maverick-17b-instruct-v1', snapshot(), marks=mark_xfail_todo),
    pytest.param('deepinfra', 'Qwen/Qwen3-32B', snapshot(), marks=mark_xfail_todo),
    ('openai', 'o3-pro', snapshot(('openai', 'o3-pro'))),
    ('anthropic', 'claude-3-haiku', snapshot(('anthropic', 'claude-3-haiku'))),
    ('anthropic', 'claude-3.7-sonnet', snapshot(('anthropic', 'claude-3-7-sonnet-latest'))),
    ('cohere_chat', 'command-a-03-2025', snapshot(('cohere', 'command-a'))),
    ('google-vertex', 'gemini-1.5-flash', snapshot(('google', 'gemini-1.5-flash'))),
    pytest.param(
        'bedrock',
        'bedrock:us.meta.llama4-maverick-17b-instruct-v1:0',
        snapshot(),
        marks=mark_xfail_todo,
    ),
    ('gemini', 'gemini-1.5-pro', snapshot(('google', 'gemini-1.5-pro'))),
    (
        'google-gla',
        'gemini-2.5-progoogle-gla:gemini-2.5-flashgoogle-gla:gemini-2.5-flash-litegoogle-gla:gemini-2.0-flashgoogle-gla:gemini-2.0-flash-litegithub:gpt-4.1github:gpt-4.1-minigithub:gpt-4ogithub:gpt-4o-minigithub:gpt-3.5-turbogithub:gpt-3.5-turbo-instruct',
        snapshot(('google', 'gemini-2.0-flash')),
    ),
    pytest.param('groq', 'openai/gpt-oss-w20b', snapshot(), marks=mark_xfail_todo),
    ('google-vertex', 'claude-sonnet-4@20250514', snapshot(('google', 'claude-4-sonnet'))),
    pytest.param('google-gla', 'gemini-2.5-flash-nano', snapshot(), marks=pytest.mark.xfail(reason='prices not found')),
    pytest.param(
        'together_ai',
        'meta-llama/Llama-3.3-70B-Instruct-Turbo',
        snapshot(('together', 'meta-llama/Llama-3.3-70B-Instruct-Turbo')),
        marks=mark_xfail_todo,
    ),
    ('openai', 'gpt-4o-mini-realtime-preview', snapshot(('openai', 'gpt-4o-mini-realtime-preview'))),
    ('google-vertex', 'gemini-1.5-flash-002', snapshot(('google', 'gemini-1.5-flash'))),
    ('gemini', 'gemini-1.5-pro-002', snapshot(('google', 'gemini-1.5-pro'))),
    pytest.param('deepinfra', 'zai-org/GLM-4.5', snapshot(), marks=mark_xfail_todo),
    pytest.param('deepinfra', 'Qwen/Qwen3-235B-A22B', snapshot(), marks=mark_xfail_todo),
    pytest.param('openrouter', 'deepseek/deepseek-r1-0528', snapshot(), marks=mark_xfail_todo),
    pytest.param('huggingface', 'moonshotai/kimi-k2-instruct', snapshot(), marks=mark_xfail_todo),
    ('google-vertex', 'gemini-2.5-pro-preview-03-25', snapshot(('google', 'gemini-2.5-pro'))),
    pytest.param('deepinfra', 'qwen/qwen3-32b', snapshot(), marks=mark_xfail_todo),
    ('anthropic', 'claude-sonnet-3.7', snapshot(('anthropic', 'claude-3-7-sonnet-latest'))),
    ('openai', 'o4-mini-high', snapshot(('openai', 'o4-mini'))),
    pytest.param('openrouter', 'moonshotai/kimi-k2', snapshot(), marks=mark_xfail_todo),
]


@pytest.mark.parametrize('provider_ref,model_ref,expected', test_cases)
def test_model_matching(provider_ref: str, model_ref: str, expected: str):
    provider = find_provider_by_id(providers, provider_ref)
    assert provider is not None
    model = provider.find_model(model_ref)
    assert model is not None

    assert (provider.id, model.id) == expected
